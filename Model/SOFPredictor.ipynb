{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "__author__ = 'aqeel'\n",
    "'''Train and evaluate a simple MLP on the Souq.com Reviews newswire topic classification task.\n",
    "GPU run command:\n",
    "    THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python examples/NNClassifiyReviews.py\n",
    "CPU run command:\n",
    "    python examples/NNClassifiyReviews.py\n",
    "'''\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.core import Dense, Merge, Dropout, RepeatVector,MaxoutDense,Activation\n",
    "from keras.layers import recurrent\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "from keras.objectives import mse as MMSE\n",
    "import theano\n",
    "import theano.tensor as K\n",
    "import math\n",
    "import random\n",
    "random.seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Read The Data\n",
    "here we read the data and orgainze it in a file to be ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3095 48\n",
      "3 1858 112\n",
      "Loading Data....\n",
      "Data Loaded\n",
      "38745\n"
     ]
    }
   ],
   "source": [
    "mydata = pd.read_csv('All_astronomy_outliered.csv',sep=',',quotechar='\"')\n",
    "\n",
    "MORE_THAN_MEAN_BY= 0\n",
    "mydata['a_words'] = map(lambda x:x.split(),mydata['body'])\n",
    "mydata['q_words'] = map(lambda x:x.split(),mydata['q_body'])\n",
    "mydata['q_bdlen'] = map(lambda x:len(x),mydata['q_words'])\n",
    "mydata['a_bdlen'] = map(lambda x:len(x),mydata['a_words'])\n",
    "Q_MAX = max(mydata['q_bdlen'])\n",
    "A_MAX = max(mydata['a_bdlen'])\n",
    "Q_MEAN = int(math.floor(np.mean(mydata['q_bdlen']))+MORE_THAN_MEAN_BY)\n",
    "A_MEAN=int(math.floor(np.mean(mydata['a_bdlen']))+MORE_THAN_MEAN_BY)\n",
    "print min(mydata['q_bdlen']),Q_MAX,Q_MEAN-MORE_THAN_MEAN_BY\n",
    "print min(mydata['a_bdlen']),A_MAX,A_MEAN-MORE_THAN_MEAN_BY\n",
    "#Q_MEAN = 38 #median\n",
    "#A_MEAN = 86 #median\n",
    "def GetDataW(splitper=0.2):\n",
    "    global mydata\n",
    "    splitper = int(math.floor(splitper * len(mydata)) + 1)\n",
    "    #Shuffle the data\n",
    "    mydata = mydata.iloc[np.random.permutation(len(mydata))]\n",
    "    mydata[:splitper].to_csv('test.csv')\n",
    "    return mydata['q_words'][splitper:].tolist(),mydata['a_words'][splitper:].tolist(),    mydata['score'][splitper:].tolist(),mydata['q_words'][:splitper].tolist(),    mydata['a_words'][:splitper].tolist(),mydata['score'][:splitper].tolist()\n",
    "\n",
    "print ('Loading Data....')\n",
    "Qx_trn,Ax_trn,y_trn,Qx_test,Ax_test,y_test= GetDataW(0.2)\n",
    "print ('Data Loaded')\n",
    "\n",
    "All_Vocabulary={}\n",
    "for i in Qx_trn+Ax_trn+Qx_test+Ax_test:\n",
    "    for element in i:\n",
    "        All_Vocabulary[element]=True\n",
    "\n",
    "All_Vocabulary= All_Vocabulary.keys()\n",
    "print len(All_Vocabulary)\n",
    "\n",
    "vocab_size = len(All_Vocabulary)+1\n",
    "word_idx = dict((c, i + 1) for i, c in enumerate(All_Vocabulary))\n",
    "\n",
    "def Vectorize():\n",
    "    global Qx_trn,Ax_trn,Qx_test,Ax_test,y_trn,y_test\n",
    "    \n",
    "    for i in range (0,len(Qx_trn)):\n",
    "        Qx_trn[i] = [word_idx[l] for l in Qx_trn[i]]\n",
    "    Qx_trn= pad_sequences(Qx_trn,Q_MEAN)\n",
    "    \n",
    "    for i in range (0,len(Ax_trn)):\n",
    "        Ax_trn[i] = [word_idx[l] for l in Ax_trn[i]]\n",
    "    Ax_trn =pad_sequences(Ax_trn,A_MEAN)\n",
    "    \n",
    "    for i in range (0,len(Qx_test)):\n",
    "        Qx_test[i] = [word_idx[l] for l in Qx_test[i]]\n",
    "    Qx_test= pad_sequences(Qx_test,Q_MEAN)\n",
    "    \n",
    "    for i in range (0,len(Ax_test)):\n",
    "        Ax_test[i] = [word_idx[l] for l in Ax_test[i]]\n",
    "    Ax_test = pad_sequences(Ax_test,A_MEAN)\n",
    "    y_trn = np.array(y_trn)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "Vectorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Vocabulary  = 38746\n",
      "Train Questions.shape = (3567, 48),Test Questions.shape(892, 48)\n",
      "Train Answers.shape = (3567, 112),Test Answers.shape(892, 112)\n",
      "Train_Y.shape = (3567,),Test_Y.shape(892,)\n",
      "Questions Max Length, Answers Max Length = 3095, 1858\n"
     ]
    }
   ],
   "source": [
    "print('All Vocabulary  = {}'.format(vocab_size))\n",
    "print('Train Questions.shape = {},Test Questions.shape{}'.format(Qx_trn.shape,Qx_test.shape))\n",
    "print('Train Answers.shape = {},Test Answers.shape{}'.format(Ax_trn.shape,Ax_test.shape))\n",
    "print('Train_Y.shape = {},Test_Y.shape{}'.format(y_trn.shape,y_test.shape))\n",
    "print('Questions Max Length, Answers Max Length = {}, {}'.format(Q_MAX, A_MAX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RNN = recurrent.LSTM\n",
    "EMBED_HIDDEN_SIZE = 100\n",
    "LSTM_HIDDEN_SIZE = 100\n",
    "#1-inf\n",
    "BATCH_SIZE = 32\n",
    "#1-inf\n",
    "EPOCHS = 2\n",
    "#Done\n",
    "#SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax\n",
    "theoptimizer = 'Adam'\n",
    "#DONE\n",
    "#0.1-0.9\n",
    "thedropout =0.5\n",
    "#DONE\n",
    "#softmax,softplus,relu,tanh,sigmoid,hard_sigmoid,linear,\n",
    "FirstActivation = 'relu'\n",
    "SecondActivation='softmax'\n",
    "#DONE\n",
    "#mean_squared_error / mse,root_mean_squared_error / rmse,mean_absolute_error / mae,mean_absolute_percentage_error / mape\n",
    "#mean_squared_logarithmic_error / msle,squared_hinge, hinge,binary_crossentropy: Also known as logloss,categorical_crossentropy: Also known as multiclass logloss. Note: using this objective requires that your labels are binary arrays of shape (nb_samples, nb_classes).\n",
    "#poisson: mean of (predictions - targets * log(predictions))# cosine_proximity: the opposite (negative) of the mean cosine proximity between predictions and targets.\n",
    "theloss='NMSE'\n",
    "#DONE\n",
    "#======================\n",
    "results = open('results.txt','a')\n",
    "results.write('\\nBatchSize:{},EPOCH:{},Optimizer:{},Dropout:{},1stActivation:{},2ndActivation:{},theloss:{},QVectorLength:{},AVectorLength:{},HIDDENSIZE:{}'\\\n",
    ".format(BATCH_SIZE,EPOCHS,theoptimizer,thedropout,FirstActivation,SecondActivation,theloss,Q_MEAN,A_MEAN,EMBED_HIDDEN_SIZE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "(None, 100)\n",
      "(None, 100)\n",
      "(None, 200)\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "\n",
    "Questions = Sequential()\n",
    "Questions.add(Embedding(vocab_size, EMBED_HIDDEN_SIZE, input_length=Q_MEAN, mask_zero=True))\n",
    "Questions.add(Dropout(thedropout))\n",
    "Questions.add(RNN(LSTM_HIDDEN_SIZE, return_sequences=False))\n",
    "\n",
    "Answers = Sequential()\n",
    "Answers.add(Embedding(vocab_size, EMBED_HIDDEN_SIZE, input_length=A_MEAN,mask_zero=True))\n",
    "Answers.add(Dropout(thedropout))\n",
    "Answers.add(RNN(LSTM_HIDDEN_SIZE, return_sequences=False))\n",
    "\n",
    "print Questions.output_shape\n",
    "print Answers.output_shape\n",
    "m = Merge([Questions, Answers], mode='concat')\n",
    "print m.output_shape\n",
    "\n",
    "def NMSE(y_true, y_pred):\n",
    "    nmse = K.mean(K.square(y_pred-y_true)/(K.mean(y_pred)*K.mean(y_true)))\n",
    "    results.write('\\n MSE IS:= {}'.format(MMSE(y_true,y_pred)))\n",
    "    return nmse\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Merge([Questions, Answers], mode='concat'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(100, activation='linear'))\n",
    "model.add(Dense(100, activation='linear'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(optimizer=theoptimizer,\n",
    "              loss=NMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                       Output Shape        Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)            (None, 48, 100)     3874600     embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)                (None, 48, 100)     0           embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                      (None, 100)         80400       dropout_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 3955000\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Questions.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                       Output Shape        Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_2 (Embedding)            (None, 112, 100)    3874600     embedding_input_2[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)                (None, 112, 100)    0           embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                      (None, 100)         80400       dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 3955000\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Answers.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                       Output Shape        Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)            (None, 48, 100)     3874600                                      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)                (None, 48, 100)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                      (None, 100)         80400                                        \n",
      "____________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)            (None, 112, 100)    3874600                                      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)                (None, 112, 100)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                      (None, 100)         80400                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)                (None, 200)         0           merge_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                    (None, 100)         20100       dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                    (None, 100)         10100       dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                    (None, 1)           101         dense_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 7940301\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Training')\n",
    "hist = model.fit([Qx_trn, Ax_trn], y_trn, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, validation_split=0.05)\n",
    "losst= model.evaluate([Qx_trn, Ax_trn], y_trn, batch_size=BATCH_SIZE)\n",
    "results.write('\\n Train loss= {}'.format(losst))\n",
    "loss= model.evaluate([Qx_test, Ax_test], y_test, batch_size=BATCH_SIZE)\n",
    "results.write('\\n Test loss = {}'.format(loss))\n",
    "results.close()\n",
    "prediction_Y= model.predict([Qx_test, Ax_test],batch_size=BATCH_SIZE)\n",
    "with open('RNNOUTPUT.csv','w') as output:\n",
    "    output.write('\\\"id\\\",\\\"relevance\\\"\\n')\n",
    "    for i in range(len(prediction_Y)):\n",
    "        output.write('{}'.format(prediction_Y[i][0])+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Output \n",
    "Copied From the Server \n",
    "The Folloiwng parameters are the same in all experiments change :\n",
    "\n",
    "theloss:NMSE,QVectorLength:50,AVectorLength:117, Optimizer:Adam\n",
    "\n",
    "EPOCH:2,HIDDENSIZE:4\n",
    "\n",
    "Train loss = 1.01326246647\n",
    "Test loss  = 1.0573939355\n",
    "\n",
    "EPOCH:2,HIDDENSIZE:10\n",
    "\n",
    "Train loss / Train accuracy = 8.17936526422 / 0.188673955764\n",
    "Test loss / test accuracy = 9.2275516912 / 0.177130044576\n",
    "\n",
    "EPOCH:50,HIDDENSIZE:4\n",
    "\n",
    "Train loss= 0.105274160135\n",
    "Test loss = 1.05210174493\n",
    "\n",
    "EPOCH:50,HIDDENSIZE:20\n",
    "\n",
    "Train loss= 0.0716473343144\n",
    "Test loss = 0.967259530797\n",
    "\n",
    "EPOCH:50,HIDDENSIZE:100\n",
    "\n",
    "Train loss= 0.0706326634774\n",
    "Test loss = 1.13603488613\n",
    "\n",
    "EPOCH:2,HIDDENSIZE:100\n",
    "\n",
    "Train loss= 0.73422428308\n",
    "Test loss = 0.813926397418\n",
    "\n",
    "**The MSE For this value is :9.695838**\n",
    "**Best Result with MSE Cost Function:**\n",
    "EPOCH:1,theloss:mse,,HIDDENSIZE:4\n",
    " Train loss  = 7.92233450552\n",
    " Test loss = 8.85901421175\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
