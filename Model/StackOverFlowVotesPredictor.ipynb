{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Read The Data\n",
    "here we read the data and orgainze it in a file to be ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "__author__ = 'aqeel'\n",
    "'''Train and evaluate a simple MLP on the Souq.com Reviews newswire topic classification task.\n",
    "GPU run command:\n",
    "    THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python examples/NNClassifiyReviews.py\n",
    "CPU run command:\n",
    "    python examples/NNClassifiyReviews.py\n",
    "'''\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.core import Dense, Merge, Dropout, RepeatVector,MaxoutDense,Activation\n",
    "from keras.layers import recurrent\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "import math\n",
    "import random\n",
    "random.seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Read The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mydata = pd.read_csv('astronomy.stackexchange.com/All.csv',sep=',',quotechar='\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mydata['body'].head(1)[0]\n",
    "for i in range(len(mydata)):\n",
    "    if isinstance(mydata['body'][i], float):\n",
    "        print i,mydata['body'][i]\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3095 50\n",
      "3 2154 117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MORE_THAN_MEAN_BY= 100\n",
    "mydata['a_words'] = map(lambda x:x.split(),mydata['body'])\n",
    "mydata['q_words'] = map(lambda x:x.split(),mydata['q_body'])\n",
    "mydata['q_bdlen'] = map(lambda x:len(x),mydata['q_words'])\n",
    "mydata['a_bdlen'] = map(lambda x:len(x),mydata['a_words'])\n",
    "Q_MAX = max(mydata['q_bdlen'])\n",
    "A_MAX = max(mydata['a_bdlen'])\n",
    "Q_MEAN = int(math.floor(np.mean(mydata['q_bdlen']))+MORE_THAN_MEAN_BY)\n",
    "A_MEAN=int(math.floor(np.mean(mydata['a_bdlen']))+MORE_THAN_MEAN_BY)\n",
    "print min(mydata['q_bdlen']),Q_MAX,Q_MEAN-MORE_THAN_MEAN_BY\n",
    "print min(mydata['a_bdlen']),A_MAX,A_MEAN-MORE_THAN_MEAN_BY\n",
    "np.median(mydata['q_score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4536"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>parent</th>\n",
       "      <th>body</th>\n",
       "      <th>q_score</th>\n",
       "      <th>q_ansrcnt</th>\n",
       "      <th>q_ViewCount</th>\n",
       "      <th>q_body</th>\n",
       "      <th>a_words</th>\n",
       "      <th>q_words</th>\n",
       "      <th>q_bdlen</th>\n",
       "      <th>a_bdlen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 8200</td>\n",
       "      <td> 8</td>\n",
       "      <td> 8192</td>\n",
       "      <td> l4 l5 point pair bodi onli stabl larger bodi l...</td>\n",
       "      <td> 6</td>\n",
       "      <td> 1</td>\n",
       "      <td> 277</td>\n",
       "      <td> usual exampl lagrang point mechan one common e...</td>\n",
       "      <td> [l4, l5, point, pair, bodi, onli, stabl, large...</td>\n",
       "      <td> [usual, exampl, lagrang, point, mechan, one, c...</td>\n",
       "      <td> 66</td>\n",
       "      <td> 35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  score  parent                                               body  \\\n",
       "0  8200      8    8192  l4 l5 point pair bodi onli stabl larger bodi l...   \n",
       "\n",
       "   q_score  q_ansrcnt  q_ViewCount  \\\n",
       "0        6          1          277   \n",
       "\n",
       "                                              q_body  \\\n",
       "0  usual exampl lagrang point mechan one common e...   \n",
       "\n",
       "                                             a_words  \\\n",
       "0  [l4, l5, point, pair, bodi, onli, stabl, large...   \n",
       "\n",
       "                                             q_words  q_bdlen  a_bdlen  \n",
       "0  [usual, exampl, lagrang, point, mechan, one, c...       66       35  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Split the data (Train,Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def GetData(splitper=0.2):\n",
    "    global mydata\n",
    "    splitper = int(math.floor(splitper * len(mydata)) + 1)\n",
    "    #Shuffle the data\n",
    "    mydata = mydata.iloc[np.random.permutation(len(mydata))]\n",
    "    return mydata['q_body'][splitper:].tolist(),mydata['body'][splitper:].tolist(),\\\n",
    "    mydata['score'][splitper:].tolist(),mydata['q_body'][:splitper].tolist(),\\\n",
    "    mydata['body'][:splitper].tolist(),mydata['score'][:splitper].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetDataW(splitper=0.2):\n",
    "    global mydata\n",
    "    splitper = int(math.floor(splitper * len(mydata)) + 1)\n",
    "    #Shuffle the data\n",
    "    mydata = mydata.iloc[np.random.permutation(len(mydata))]\n",
    "    mydata[:splitper].to_csv('test.csv')\n",
    "    return mydata['q_words'][splitper:].tolist(),mydata['a_words'][splitper:].tolist(),\\\n",
    "    mydata['score'][splitper:].tolist(),mydata['q_words'][:splitper].tolist(),\\\n",
    "    mydata['a_words'][:splitper].tolist(),mydata['score'][:splitper].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data....\n",
      "Data Loaded\n"
     ]
    }
   ],
   "source": [
    "print ('Loading Data....')\n",
    "Qx_trn,Ax_trn,y_trn,Qx_test,Ax_test,y_test= GetDataW(0.2)\n",
    "print ('Data Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60644\n"
     ]
    }
   ],
   "source": [
    "All_Vocabulary={}\n",
    "for i in Qx_trn+Ax_trn+Qx_test+Ax_test:\n",
    "    for element in i:\n",
    "        All_Vocabulary[element]=True\n",
    "\n",
    "All_Vocabulary= All_Vocabulary.keys()\n",
    "print len(All_Vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AllQuestionsWords = mydata.drop_duplicates('parent')['q_words']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print('Vectorizing sequence data...')\n",
    "tokenizer = Tokenizer(nb_words=max_words)\n",
    "tokenizer.fit_on_texts(AllQuestionsWords+mydata['body'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = len(All_Vocabulary)+1\n",
    "word_idx = dict((c, i + 1) for i, c in enumerate(All_Vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "print('Vectorizing sequence data...')\n",
    "tokenizer = Tokenizer(nb_words=10)\n",
    "tokenizer.fit_on_texts(mydata['body'][0])\n",
    "t=tokenizer.texts_to_sequences(mydata['body'][0])\n",
    "'''t[np.all(t==[9], axis=0)]'''\n",
    "print [x[0] for x in t if x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vectorize():\n",
    "    global Qx_trn,Ax_trn,Qx_test,Ax_test,y_trn,y_test\n",
    "    \n",
    "    for i in range (0,len(Qx_trn)):\n",
    "        Qx_trn[i] = [word_idx[l] for l in Qx_trn[i]]\n",
    "    Qx_trn= pad_sequences(Qx_trn,Q_MEAN)\n",
    "    \n",
    "    for i in range (0,len(Ax_trn)):\n",
    "        Ax_trn[i] = [word_idx[l] for l in Ax_trn[i]]\n",
    "    Ax_trn =pad_sequences(Ax_trn,A_MEAN)\n",
    "    \n",
    "    for i in range (0,len(Qx_test)):\n",
    "        Qx_test[i] = [word_idx[l] for l in Qx_test[i]]\n",
    "    Qx_test= pad_sequences(Qx_test,Q_MEAN)\n",
    "    \n",
    "    for i in range (0,len(Ax_test)):\n",
    "        Ax_test[i] = [word_idx[l] for l in Ax_test[i]]\n",
    "    Ax_test = pad_sequences(Ax_test,A_MEAN)\n",
    "    y_trn = np.array(y_trn)\n",
    "    y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Vectorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Vocabulary  = 60645\n",
      "Train Questions.shape = (3628, 150),Test Questions.shape(908, 150)\n",
      "Train Answers.shape = (3628, 217),Test Answers.shape(908, 217)\n",
      "Train_Y.shape = (3628,),Test_Y.shape(908,)\n",
      "Questions Max Length, Answers Max Length = 3095, 2154\n"
     ]
    }
   ],
   "source": [
    "print('All Vocabulary  = {}'.format(vocab_size))\n",
    "print('Train Questions.shape = {},Test Questions.shape{}'.format(Qx_trn.shape,Qx_test.shape))\n",
    "print('Train Answers.shape = {},Test Answers.shape{}'.format(Ax_trn.shape,Ax_test.shape))\n",
    "print('Train_Y.shape = {},Test_Y.shape{}'.format(y_trn.shape,y_test.shape))\n",
    "print('Questions Max Length, Answers Max Length = {}, {}'.format(Q_MAX, A_MAX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Sequence The Training and Testing Set\n",
    "Qx_trn = tokenizer.texts_to_sequences(Qx_trn)\n",
    "Ax_trn= tokenizer.texts_to_sequences(Ax_trn)\n",
    "Qx_test = tokenizer.texts_to_sequences(Qx_test)\n",
    "Ax_test= tokenizer.texts_to_sequences(Ax_test)\n",
    "print ('Sequences : Q_train:{},A_train:{},Q_test:{},A_test:{}'\\\n",
    "       .format(len(Qx_trn),len(Ax_trn),len(Qx_test),len(Ax_test)))\n",
    "\n",
    "Qx_trn = tokenizer.sequences_to_matrix(Qx_trn, mode=sequencemode)\n",
    "Ax_trn= tokenizer.sequences_to_matrix(Ax_trn, mode=sequencemode)\n",
    "Qx_test = tokenizer.sequences_to_matrix(Qx_test, mode=sequencemode)\n",
    "Ax_test= tokenizer.sequences_to_matrix(Ax_test, mode=sequencemode)\n",
    "       \n",
    "print ('Shapes : Q_train:{},A_train:{},Q_test:{},A_test:{}'\\\n",
    "       .format(Qx_trn.shape,Ax_trn.shape,Qx_test.shape,Ax_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RNN = recurrent.LSTM\n",
    "EMBED_HIDDEN_SIZE = 50\n",
    "#1-inf\n",
    "BATCH_SIZE = 32\n",
    "#1-inf\n",
    "EPOCHS = 2\n",
    "#Done\n",
    "#SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax\n",
    "theoptimizer = 'RMSprop'\n",
    "#DONE\n",
    "#0.1-0.9\n",
    "thedropout =0.5\n",
    "#DONE\n",
    "#softmax,softplus,relu,tanh,sigmoid,hard_sigmoid,linear,\n",
    "FirstActivation = 'relu'\n",
    "SecondActivation='softmax'\n",
    "#DONE\n",
    "#mean_squared_error / mse,root_mean_squared_error / rmse,mean_absolute_error / mae,mean_absolute_percentage_error / mape\n",
    "#mean_squared_logarithmic_error / msle,squared_hinge, hinge,binary_crossentropy: Also known as logloss,categorical_crossentropy: Also known as multiclass logloss. Note: using this objective requires that your labels are binary arrays of shape (nb_samples, nb_classes).\n",
    "#poisson: mean of (predictions - targets * log(predictions))# cosine_proximity: the opposite (negative) of the mean cosine proximity between predictions and targets.\n",
    "theloss='mse'\n",
    "#DONE\n",
    "#modes: binary, count, tfidf, freq (best test accuracy count),(best Train Accuracy binary)\n",
    "sequencemode = 'count'\n",
    "#======================\n",
    "results = open('results.txt','a')\n",
    "results.write('\\n'+str(BATCH_SIZE)+','+str(EPOCHS)+','+theoptimizer+','+str(thedropout)+','+FirstActivation+','+SecondActivation + ','+theloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "\n",
    "Questions = Sequential()\n",
    "Questions.add(Embedding(vocab_size, EMBED_HIDDEN_SIZE, input_length=Q_MEAN, mask_zero=True))\n",
    "Questions.add(Dropout(thedropout))\n",
    "Questions.add(RNN(EMBED_HIDDEN_SIZE, return_sequences=False))\n",
    "\n",
    "Answers = Sequential()\n",
    "Answers.add(Embedding(vocab_size, EMBED_HIDDEN_SIZE, input_length=A_MEAN,mask_zero=True))\n",
    "Answers.add(Dropout(thedropout))\n",
    "Answers.add(RNN(EMBED_HIDDEN_SIZE, return_sequences=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                       Output Shape        Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)            (None, 150, 50)     3032250     embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)                (None, 150, 50)     0           embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                      (None, 50)          20200       dropout_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 3052450\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Questions.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 50)\n",
      "(None, 50)\n",
      "(None, 100)\n"
     ]
    }
   ],
   "source": [
    "print Questions.output_shape\n",
    "print Answers.output_shape\n",
    "m = Merge([Questions, Answers], mode='concat')\n",
    "print m.output_shape\n",
    "results.write('\\n Test loss / test accuracy = {:.4f} / {:.4f}'.format(1.0, 1.0))\n",
    "results.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Merge([Questions, Answers], mode='concat'))\n",
    "#model.add(RNN(EMBED_HIDDEN_SIZE, return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=theoptimizer,\n",
    "              loss=theloss,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                       Output Shape        Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)            (None, 150, 50)     3032250                                      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)                (None, 150, 50)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                      (None, 50)          20200                                        \n",
      "____________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)            (None, 217, 50)     3032250                                      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)                (None, 217, 50)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                      (None, 50)          20200                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)                (None, 100)         0           merge_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                    (None, 1)           101         dropout_3[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 6105001\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-762664f64f12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mQx_trn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAx_trn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_trn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mQx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAx_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n Test loss / test accuracy = {:.4f} / {:.4f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    400\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m                               sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[0;32m   1007\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mslice_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_at\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_at\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1008\u001b[0m             \u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_sample_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mslice_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_at\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_at\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1009\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1010\u001b[0m             \u001b[0mval_f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1011\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_make_test_function\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    674\u001b[0m                                             \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m                                             \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_updates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m                                             **self._function_kwargs)\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_predict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[0;32m    507\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Invalid argument '%s' passed to K.function\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    510\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m                                         \u001b[0mallow_input_downcast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m                                         \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'warn'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 495\u001b[1;33m                                         **kwargs)\n\u001b[0m\u001b[0;32m    496\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function.pyc\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    318\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m                    output_keys=output_keys)\n\u001b[0m\u001b[0;32m    321\u001b[0m     \u001b[1;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;31m# borrowed used defined inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mpfunc\u001b[1;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m    477\u001b[0m                          \u001b[0maccept_inplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m                          \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 479\u001b[1;33m                          output_keys=output_keys)\n\u001b[0m\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36morig_function\u001b[1;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m   1774\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1775\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1776\u001b[1;33m                    \u001b[0moutput_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1777\u001b[0m             defaults)\n\u001b[0;32m   1778\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, mode, accept_inplace, function_builder, profile, on_unused_input, fgraph, output_keys)\u001b[0m\n\u001b[0;32m   1454\u001b[0m                         optimizer, inputs, outputs)\n\u001b[0;32m   1455\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1456\u001b[1;33m                     \u001b[0moptimizer_profile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1458\u001b[0m                 \u001b[0mend_optimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, fgraph)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \"\"\"\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0madd_requirements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, fgraph, *args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0morig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morig\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, fgraph)\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m                 \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m                 \u001b[0msub_prof\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m                 \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m                 \u001b[0msub_profs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_prof\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, fgraph, *args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0morig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morig\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/tensor/opt.pyc\u001b[0m in \u001b[0;36minplace_elemwise_optimizer\u001b[1;34m(fgraph)\u001b[0m\n\u001b[0;32m    391\u001b[0m                         \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_r\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m                             fgraph.replace(r, new_r,\n\u001b[1;32m--> 393\u001b[1;33m                                            reason=\"inplace_elemwise_optimizer\")\n\u001b[0m\u001b[0;32m    394\u001b[0m                         \u001b[0mnb_change_no_validate\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mnb_change_no_validate\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mcheck_each_change\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/fg.pyc\u001b[0m in \u001b[0;36mreplace\u001b[1;34m(self, r, new_r, reason, verbose)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclients\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# copy the client list for iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'output'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchange_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_r\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreason\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[1;31m# sometimes the following is triggered.  If you understand why, please explain to James.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/fg.pyc\u001b[0m in \u001b[0;36mchange_input\u001b[1;34m(self, node, i, new_r, reason)\u001b[0m\n\u001b[0;32m    532\u001b[0m         \u001b[1;31m# transaction will be reverted later.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         self.execute_callbacks('on_change_input', node, i,\n\u001b[1;32m--> 534\u001b[1;33m                                r, new_r, reason=reason)\n\u001b[0m\u001b[0;32m    535\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mprune\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__remove_clients__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/fg.pyc\u001b[0m in \u001b[0;36mexecute_callbacks\u001b[1;34m(self, name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    664\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 666\u001b[1;33m                 \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    667\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m                 \u001b[1;31m# this is safe because there is no work done inside the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('Training')\n",
    "hist = model.fit([Qx_trn, Ax_trn], y_trn, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, validation_split=0.05)\n",
    "loss, acc = model.evaluate([Qx_test, Ax_test], y_test, batch_size=BATCH_SIZE)\n",
    "results.write('\\n Test loss / test accuracy = {:.4f} / {:.4f}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#This results copied after executing the code on juur.grid.eenet.ee\n",
    "BatchSize:32,EPOCH:2,Optimizer:Adam,Dropout:0.5,2ndActivation:softmax,thelossmse,QVectorLength:150,AVectorLength:217\n",
    " Train loss / Train accuracy = 15.5472828403 / 0.158765159876\n",
    " Test loss / test accuracy = 20.7112115532 / 0.140969163061\n",
    "BatchSize:32,EPOCH:2,Optimizer:Adam,Dropout:0.5,2ndActivation:softmax,thelossmse,QVectorLength:250,AVectorLength:317\n",
    " Train loss / Train accuracy = 16.2962467799 / 0.134785005521\n",
    " Test loss / test accuracy = 21.181909788 / 0.135462555132\n",
    "BatchSize:32,EPOCH:2,Optimizer:Adam,Dropout:0.5,2ndActivation:softmax,thelossmse,QVectorLength:50,AVectorLength:117\n",
    " Train loss / Train accuracy = 16.3322546338 / 0.136714443228\n",
    " Test loss / test accuracy = 21.1259150232 / 0.136563876718\n",
    "BatchSize:32,EPOCH:200,Optimizer:Adam,Dropout:0.5,2ndActivation:softmax,thelossmse,QVectorLength:50,AVectorLength:117\n",
    " Train loss / Train accuracy = 0.586722035606 / 0.909316427784\n",
    " Test loss / test accuracy = 21.4848160261 / 0.147577092544\n",
    "BatchSize:32,EPOCH:100,Optimizer:Adam,Dropout:0.5,2ndActivation:softmax,thelossmse,QVectorLength:50,AVectorLength:117\n",
    " Train loss / Train accuracy = 0.66182425444 / 0.881477398015\n",
    " Test loss / test accuracy = 21.3947613082 / 0.157488986915\n",
    "BatchSize:32,EPOCH:50,Optimizer:Adam,Dropout:0.5,2ndActivation:softmax,thelossmse,QVectorLength:50,AVectorLength:117\n",
    " Train loss / Train accuracy = 0.797981166787 / 0.780319735391\n",
    " Test loss / test accuracy = 20.6134651453 / 0.150881057269\n",
    "BatchSize:32,EPOCH:50,Optimizer:Adam,Dropout:0.5,2ndActivation:softmax,thelossmse,QVectorLength:50,AVectorLength:117\n",
    " Train loss / Train accuracy = 0.835777364992 / 0.766538037494\n",
    " Test loss / test accuracy = 20.5429394088 / 0.138766519824\n",
    "BatchSize:32,EPOCH:150,Optimizer:Adam,Dropout:0.5,2ndActivation:softmax,thelossmse,QVectorLength:50,AVectorLength:117\n",
    " Train loss / Train accuracy = 0.693766769839 / 0.877618522618\n",
    " Test loss / test accuracy = 21.203188287 / 0.132158590341"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
